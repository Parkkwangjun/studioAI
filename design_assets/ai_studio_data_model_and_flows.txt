AI STUDIO – DATA MODEL & KEY FLOWS
==================================

DATA MODEL (RELATIONAL)
-----------------------

Project
- id (uuid, pk)
- title (string)
- description (string, nullable)
- platform (string)
- category (string)
- tone (string)
- targetLength (string)
- language (string)
- status (string: draft/in-progress/completed)
- createdAt (datetime)
- updatedAt (datetime)

Scene
- id (uuid, pk)
- projectId (fk → Project.id)
- index (int)
- text (text)
- notes (text, nullable)
- createdAt
- updatedAt

AudioClip
- id (uuid, pk)
- sceneId (fk → Scene.id)
- url (string)
- provider (string)
- voiceId (string)
- speed (float)
- durationSec (float)
- status (string: pending/ready/failed)
- error (text, nullable)
- createdAt
- updatedAt

ImageAsset
- id (uuid, pk)
- projectId (fk → Project.id)
- sceneId (fk → Scene.id, nullable for project-level image)
- url (string)
- prompt (text)
- model (string)
- isMain (boolean)
- status (string: pending/ready/failed)
- error (text, nullable)
- createdAt
- updatedAt

VideoClip
- id (uuid, pk)
- projectId (fk → Project.id)
- url (string)
- aspectRatio (string)
- durationSec (float)
- status (string: pending/rendering/ready/failed)
- error (text, nullable)
- createdAt
- updatedAt

Settings
- id (single row or per-user)
- defaultLanguage (string)
- defaultTone (string)
- defaultImageStyle (string)
- defaultTtsVoice (string)
- scriptModel (string)
- imageModel (string)
- ttsProvider (string)
- videoProvider (string)
- createdAt
- updatedAt

KEY FLOWS (BACKEND PERSPECTIVE)
-------------------------------

1) Generate Script
   - Input: prompt + options
   - Steps:
     1. Call LLM to get raw script text.
     2. Split text into scenes (list of strings).
     3. Create Project row.
     4. Create Scene rows (index 1..N).
   - Output: project + scenes (mirrors frontend expectations).

2) Generate TTS (single scene)
   - Input: sceneId, voiceId, speed.
   - Steps:
     1. Fetch Scene.
     2. Call TTS provider with scene.text.
     3. Store AudioClip row with url/status.
   - Output: AudioClip.

3) Generate TTS (batch)
   - Input: projectId, shared voiceId/speed.
   - Steps:
     1. Fetch Scenes for project in order.
     2. For each scene, run single-scene flow (possibly in parallel with limits).

4) Generate Image
   - Input: sceneId, stylePrompt, modelOptions.
   - Steps:
     1. Fetch Scene + Project for context.
     2. Build prompt (scene.text + stylePrompt).
     3. Call image model.
     4. Store ImageAsset row.
   - Output: ImageAsset.

5) Generate Video
   - Input: projectId or list of imageIds + options.
   - Steps:
     1. Resolve list of image urls.
     2. Call video engine with required options.
     3. Create VideoClip row with status=pending/rendering.
     4. Update when finished.
   - Output: VideoClip.

These models and flows are enough for any engineer or agent to implement persistent storage and core logic that matches the rest of the specification.
